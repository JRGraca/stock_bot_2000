{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_ta as pta\n",
    "import ta\n",
    "# from datapackage import Package\n",
    "# from selenium import webdriver\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "import yfinance as yf\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import datetime as dt\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import array\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import graphviz\n",
    "import pydot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "steps = 20\n",
    "epochs = 50\n",
    "nodes_per_layer = 64\n",
    "shift = -1\n",
    "batch_size = 20\n",
    "loss_function = \"mean_squared_error\"\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"NVDA.csv\"\n",
    "ticker_code = file.replace(\".csv\", \"\")\n",
    "dataset = pd.read_csv(\"data/\" + file)\n",
    "shift = -1\n",
    "dataset = dataset.drop(columns=[\"Date\", \"Dividends\", \"Stock Splits\"])\n",
    "dataset = dataset.dropna()\n",
    "train_set_len = int(len(dataset) * 0.8)\n",
    "train_set = dataset[:train_set_len]\n",
    "test_set = dataset[train_set_len:]\n",
    "X_train = train_set.drop(columns=[\"Close\"])[:shift]\n",
    "y_train = train_set[\"Close\"].shift(shift).dropna()\n",
    "X_test = test_set.drop(columns=[\"Close\"])[:shift]\n",
    "y_test = test_set[\"Close\"].shift(shift).dropna()\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "X_train_scaled = x_scaler.fit_transform(X_train)\n",
    "y_train_scaled = y_scaler.fit_transform(np.array(y_train).reshape(-1,1))\n",
    "X_test_scaled = x_scaler.transform(X_test)\n",
    "y_test_scaled = y_scaler.transform(np.array(y_test).reshape(-1,1))\n",
    "pd.to_pickle(x_scaler, \"scalers/\" + str(ticker_code) + \"_x_scaler.pkl\")\n",
    "pd.to_pickle(y_scaler, \"scalers/\" + str(ticker_code) + \"_y_scaler.pkl\")\n",
    "pd.to_pickle(train_set, \"train_sets/\" + ticker_code + \"_train_set.pkl\")\n",
    "pd.to_pickle(test_set, \"test_sets/\" + ticker_code + \"_test_set.pkl\")\n",
    "pd.to_pickle(X_train, \"sets/X_train/\" + ticker_code + \"_X_train.pkl\")\n",
    "pd.to_pickle(X_test, \"sets/X_test/\" + ticker_code + \"_X_test.pkl\")\n",
    "pd.to_pickle(y_train, \"sets/y_train/\" + ticker_code + \"_y_train.pkl\")\n",
    "pd.to_pickle(y_test, \"sets/y_test/\" + ticker_code + \"_y_test.pkl\")\n",
    "pd.to_pickle(X_train_scaled, \"sets/X_train/\" + ticker_code + \"_X_train_scaled.pkl\")\n",
    "pd.to_pickle(X_test_scaled, \"sets/X_test/\" + ticker_code + \"_X_test_scaled.pkl\")\n",
    "pd.to_pickle(y_train_scaled, \"sets/y_train/\" + ticker_code + \"_y_train_scaled.pkl\")\n",
    "pd.to_pickle(y_test_scaled, \"sets/y_test/\" + ticker_code + \"_y_test_scaled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "240/240 [==============================] - 18s 36ms/step - loss: 0.0024\n",
      "Epoch 2/50\n",
      "240/240 [==============================] - 10s 41ms/step - loss: 3.0902e-04\n",
      "Epoch 3/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.9453e-04\n",
      "Epoch 4/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.3366e-04\n",
      "Epoch 5/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 3.0467e-04\n",
      "Epoch 6/50\n",
      "240/240 [==============================] - 9s 35ms/step - loss: 2.5783e-04\n",
      "Epoch 7/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 3.8368e-04\n",
      "Epoch 8/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.7940e-04\n",
      "Epoch 9/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.3837e-04\n",
      "Epoch 10/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.8957e-04\n",
      "Epoch 11/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.3579e-04\n",
      "Epoch 12/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.3247e-04\n",
      "Epoch 13/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.5891e-04\n",
      "Epoch 14/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.4887e-04\n",
      "Epoch 15/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.8615e-04\n",
      "Epoch 16/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.9691e-04\n",
      "Epoch 17/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 2.6360e-04\n",
      "Epoch 18/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.4111e-04\n",
      "Epoch 19/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.5504e-04\n",
      "Epoch 20/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.9005e-04\n",
      "Epoch 21/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.5221e-04\n",
      "Epoch 22/50\n",
      "240/240 [==============================] - 9s 38ms/step - loss: 1.8450e-04\n",
      "Epoch 23/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.7732e-04\n",
      "Epoch 24/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.5100e-04\n",
      "Epoch 25/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.7243e-04\n",
      "Epoch 26/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.7329e-04\n",
      "Epoch 27/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.9617e-04\n",
      "Epoch 28/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.2821e-04\n",
      "Epoch 29/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 2.7298e-04\n",
      "Epoch 30/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.2032e-04\n",
      "Epoch 31/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.0939e-04\n",
      "Epoch 32/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.1286e-04\n",
      "Epoch 33/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.0333e-04\n",
      "Epoch 34/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.5490e-04\n",
      "Epoch 35/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.0481e-04\n",
      "Epoch 36/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.1423e-04\n",
      "Epoch 37/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.0866e-04\n",
      "Epoch 38/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 9.6757e-05\n",
      "Epoch 39/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.2743e-04\n",
      "Epoch 40/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.0725e-04\n",
      "Epoch 41/50\n",
      "240/240 [==============================] - 9s 36ms/step - loss: 1.1252e-04\n",
      "Epoch 42/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 9.6523e-05\n",
      "Epoch 43/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 9.7197e-05\n",
      "Epoch 44/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.5314e-04\n",
      "Epoch 45/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 1.0485e-04\n",
      "Epoch 46/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 8.6832e-05\n",
      "Epoch 47/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 9.1768e-05\n",
      "Epoch 48/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 6.8276e-05\n",
      "Epoch 49/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 9.3336e-05\n",
      "Epoch 50/50\n",
      "240/240 [==============================] - 9s 37ms/step - loss: 9.5395e-05\n",
      "37/37 [==============================] - 3s 14ms/step - loss: 2.3207\n",
      "NVDA processing finished\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\dropout_3\n",
      "......vars\n",
      "...layers\\dropout_4\n",
      "......vars\n",
      "...layers\\dropout_5\n",
      "......vars\n",
      "...layers\\lstm\n",
      "......vars\n",
      "...layers\\lstm\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\lstm_1\n",
      "......vars\n",
      "...layers\\lstm_1\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\lstm_2\n",
      "......vars\n",
      "...layers\\lstm_2\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\lstm_3\n",
      "......vars\n",
      "...layers\\lstm_3\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\lstm_4\n",
      "......vars\n",
      "...layers\\lstm_4\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\lstm_5\n",
      "......vars\n",
      "...layers\\lstm_5\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\lstm_6\n",
      "......vars\n",
      "...layers\\lstm_6\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........29\n",
      ".........3\n",
      ".........30\n",
      ".........31\n",
      ".........32\n",
      ".........33\n",
      ".........34\n",
      ".........35\n",
      ".........36\n",
      ".........37\n",
      ".........38\n",
      ".........39\n",
      ".........4\n",
      ".........40\n",
      ".........41\n",
      ".........42\n",
      ".........43\n",
      ".........44\n",
      ".........45\n",
      ".........46\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2022-11-30 11:21:54         7661\n",
      "metadata.json                                  2022-11-30 11:21:54           64\n",
      "variables.h5                                   2022-11-30 11:21:54      2662184\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = pd.read_pickle(\"sets/X_train/\" + ticker_code + \"_X_train_scaled.pkl\")\n",
    "y_train_scaled = pd.read_pickle(\"sets/y_train/\" + ticker_code + \"_y_train_scaled.pkl\")\n",
    "X_train_list = []\n",
    "for i in range(steps, len(X_train_scaled)):\n",
    "\tX_train_list.append(X_train_scaled[i-steps:i])\n",
    "X_train_list = np.array(X_train_list)\n",
    "model = Sequential()\n",
    "model.add(LSTM(nodes_per_layer, activation='relu', input_shape=(steps, X_train_list.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(LSTM(nodes_per_layer, return_sequences=True))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(LSTM(nodes_per_layer, return_sequences=True))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(LSTM(nodes_per_layer, return_sequences=True))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(LSTM(nodes_per_layer, return_sequences=True))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(LSTM(nodes_per_layer, return_sequences=True))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(LSTM(nodes_per_layer, return_sequences=False))\n",
    "model.add(Dense(units=1, activation='relu'))\n",
    "model.compile(optimizer='adam', loss=loss_function)\n",
    "model.fit(X_train_list, y_train_scaled[:(steps * shift)], epochs=epochs, batch_size=batch_size)\n",
    "X_test_scaled = pd.read_pickle(\"sets/X_test/\" + ticker_code + \"_X_test_scaled.pkl\")\n",
    "y_test_scaled = pd.read_pickle(\"sets/y_test/\" + ticker_code + \"_y_test_scaled.pkl\")\n",
    "X_test_list = []\n",
    "for i in range(steps, len(X_test_scaled)):\n",
    "\tX_test_list.append(X_test_scaled[i-steps:i])\n",
    "X_test_list = np.array(X_test_list)\n",
    "score = model.evaluate(X_test_list, y_test_scaled[:(steps * -1)])\n",
    "print(f\"{ticker_code} processing finished\")\n",
    "pd.to_pickle(model, \"models/\" + ticker_code + \"_score_\" + str(round(score, 2)) + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1669814621.9930823"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, time\n",
    "\n",
    "ticker_code = \"MSFT\"\n",
    "ticker = yf.Ticker(ticker_code.replace(\".\", \"-\"))\n",
    "twenty_days_ago = np.busday_offset(dates=dt.date.today(), offsets=-20, roll='backward')\n",
    "raw_input = ticker.history(start=str(twenty_days_ago))\n",
    "# if len(input) != 20:\n",
    "# \tprint(\"ERROR\")\n",
    "# len(input)\n",
    "original_input = raw_input.reset_index().drop(columns=[\"Date\", \"Dividends\", \"Stock Splits\", \"Close\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Ironhack\\Final Project\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m price_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m price \u001b[39min\u001b[39;00m list_of_prices:\n\u001b[0;32m     15\u001b[0m \t\u001b[39m#print(pd.DataFrame([price]))\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \tpd\u001b[39m.\u001b[39;49mconcat([price_df,[price\u001b[39m.\u001b[39;49mkeys(), price\u001b[39m.\u001b[39;49mvalues()]], axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, ignore_index\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     17\u001b[0m \tdisplay(price_df)\n\u001b[0;32m     18\u001b[0m price_df\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\envs\\final-project\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\envs\\final-project\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mobjs\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[39m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m         objs,\n\u001b[0;32m    370\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    371\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m    372\u001b[0m         join\u001b[39m=\u001b[39;49mjoin,\n\u001b[0;32m    373\u001b[0m         keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[0;32m    374\u001b[0m         levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[0;32m    375\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    376\u001b[0m         verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[0;32m    377\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    378\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    379\u001b[0m     )\n\u001b[0;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32md:\\ProgramFiles\\Anaconda\\envs\\final-project\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:458\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[0;32m    454\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    455\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot concatenate object of type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(obj)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39monly Series and DataFrame objs are valid\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         )\n\u001b[1;32m--> 458\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    460\u001b[0m     ndims\u001b[39m.\u001b[39madd(obj\u001b[39m.\u001b[39mndim)\n\u001b[0;32m    462\u001b[0m \u001b[39m# get the sample\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[39m# want the highest ndim that we have, and must be non-empty\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[39m# unless all objs are empty\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "top_25 = [\"AAPL\", \"MSFT\", \"AMZN\", \"TSLA\", \"GOOGL\", \"BRK.B\", \"UNH\", \"JNJ\", \"XOM\", \"JPM\", \"META\", \"V\", \"PG\", \"NVDA\", \"HD\", \"CVX\", \"LLY\", \"MA\", \"ABBV\", \"PFE\", \"MRK\", \"PEP\", \"BAC\", \"KO\"]\n",
    "list_of_prices = []\n",
    "print(os.getcwd())\n",
    "for i in top_25:\n",
    "\tticker = yf.Ticker(i.replace(\".\", \"-\"))\n",
    "\thist = ticker.history(end = dt.date.today(), start = str(np.busday_offset(dates=dt.date.today(), offsets=-20, roll='backward')))\n",
    "\tif (os.path.isdir(r\"D:\\Documents\\Ironhack\\Final Project\\Flask\\recent_history\") == False):\n",
    "\t\tos.mkdir(r\"D:\\Documents\\Ironhack\\Final Project\\Flask\\recent_history\")\n",
    "\tfor csv in os.listdir(r\"D:\\Documents\\Ironhack\\Final Project\\Flask\\recent_history\"):\n",
    "\t\tos.remove(csv)\n",
    "\tpd.DataFrame(hist).to_csv(\"recent_history/\" + i + \"_last_20_days.csv\")\n",
    "\tlist_of_prices.append({\"Stock\":i, \"Price\":round(hist[\"Close\"][len(hist) - 1], 2)})\n",
    "price_df = pd.DataFrame()\n",
    "for price in list_of_prices:\n",
    "\t#print(pd.DataFrame([price]))\n",
    "\tpd.concat([price_df,[price.keys(), price.values()]], axis=0, ignore_index=1)\n",
    "\tdisplay(price_df)\n",
    "price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pd.read_pickle(\"scalers/\" + ticker_code + \"_x_scaler.pkl\")\n",
    "input = sc.transform(original_input)\n",
    "input.shape\n",
    "input = input.reshape(-1, input.shape[0], input.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file... - MSFT_score_10.59.pkl\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2022-11-29 11:50:26         7695\n",
      "metadata.json                                  2022-11-29 11:50:26           64\n",
      "variables.h5                                   2022-11-29 11:50:26      2662184\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...layers\\dropout_2\n",
      "......vars\n",
      "...layers\\dropout_3\n",
      "......vars\n",
      "...layers\\dropout_4\n",
      "......vars\n",
      "...layers\\dropout_5\n",
      "......vars\n",
      "...layers\\lstm\n",
      "......vars\n",
      "...layers\\lstm\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\lstm_1\n",
      "......vars\n",
      "...layers\\lstm_1\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\lstm_2\n",
      "......vars\n",
      "...layers\\lstm_2\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\lstm_3\n",
      "......vars\n",
      "...layers\\lstm_3\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\lstm_4\n",
      "......vars\n",
      "...layers\\lstm_4\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\lstm_5\n",
      "......vars\n",
      "...layers\\lstm_5\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\lstm_6\n",
      "......vars\n",
      "...layers\\lstm_6\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........29\n",
      ".........3\n",
      ".........30\n",
      ".........31\n",
      ".........32\n",
      ".........33\n",
      ".........34\n",
      ".........35\n",
      ".........36\n",
      ".........37\n",
      ".........38\n",
      ".........39\n",
      ".........4\n",
      ".........40\n",
      ".........41\n",
      ".........42\n",
      ".........43\n",
      ".........44\n",
      ".........45\n",
      ".........46\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n"
     ]
    }
   ],
   "source": [
    "def get_model(stock):\n",
    "\tfor file in os.listdir(\"models\"):\n",
    "\t\tif file.startswith(stock):\n",
    "\t\t\tprint(\"Reading file... - \" + file)\n",
    "\t\t\treturn pd.read_pickle(\"models/\" + file)\n",
    "\n",
    "model = get_model(ticker_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[35.117893]], dtype=float32)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sc = pd.read_pickle(\"scalers/\" + ticker_code + \"_y_scaler.pkl\")\n",
    "y_sc.inverse_transform(model.predict(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 4s 28ms/step - loss: 10.5947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.594701766967773"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = pd.read_pickle(\"sets/X_test/\" + ticker_code + \"_X_test_scaled.pkl\")\n",
    "y_test_scaled = pd.read_pickle(\"sets/y_test/\" + ticker_code + \"_y_test_scaled.pkl\")\n",
    "X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], -1)\n",
    "steps = 20\n",
    "X_test_list = []\n",
    "for i in range(steps, len(X_test_scaled)):\n",
    "\tX_test_list.append(X_test_scaled[i-steps:i])\n",
    "X_test_list = np.array(X_test_list)\n",
    "model.evaluate(X_test_list, y_test_scaled[:(steps * -1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-02 00:00:00-04:00</th>\n",
       "      <td>228.815173</td>\n",
       "      <td>230.649998</td>\n",
       "      <td>219.421632</td>\n",
       "      <td>219.481476</td>\n",
       "      <td>38407000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-03 00:00:00-04:00</th>\n",
       "      <td>219.471488</td>\n",
       "      <td>219.790596</td>\n",
       "      <td>213.378658</td>\n",
       "      <td>213.647903</td>\n",
       "      <td>36633900</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-04 00:00:00-04:00</th>\n",
       "      <td>216.938633</td>\n",
       "      <td>220.967272</td>\n",
       "      <td>212.830200</td>\n",
       "      <td>220.767838</td>\n",
       "      <td>36767800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-07 00:00:00-05:00</th>\n",
       "      <td>221.366164</td>\n",
       "      <td>227.768121</td>\n",
       "      <td>220.658153</td>\n",
       "      <td>227.229630</td>\n",
       "      <td>33498000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-08 00:00:00-05:00</th>\n",
       "      <td>228.057301</td>\n",
       "      <td>230.999008</td>\n",
       "      <td>225.205338</td>\n",
       "      <td>228.226822</td>\n",
       "      <td>28192500</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-09 00:00:00-05:00</th>\n",
       "      <td>226.731038</td>\n",
       "      <td>227.987506</td>\n",
       "      <td>223.699587</td>\n",
       "      <td>223.879074</td>\n",
       "      <td>27852900</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-10 00:00:00-05:00</th>\n",
       "      <td>234.768379</td>\n",
       "      <td>242.646187</td>\n",
       "      <td>234.339595</td>\n",
       "      <td>242.297165</td>\n",
       "      <td>46268000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-11 00:00:00-05:00</th>\n",
       "      <td>242.307141</td>\n",
       "      <td>247.293090</td>\n",
       "      <td>241.250107</td>\n",
       "      <td>246.415558</td>\n",
       "      <td>34600900</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-14 00:00:00-05:00</th>\n",
       "      <td>241.309951</td>\n",
       "      <td>243.224554</td>\n",
       "      <td>238.537765</td>\n",
       "      <td>240.871185</td>\n",
       "      <td>31123300</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-15 00:00:00-05:00</th>\n",
       "      <td>244.969641</td>\n",
       "      <td>246.305872</td>\n",
       "      <td>239.355458</td>\n",
       "      <td>241.290009</td>\n",
       "      <td>31390100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-16 00:00:00-05:00</th>\n",
       "      <td>242.789993</td>\n",
       "      <td>243.800003</td>\n",
       "      <td>240.419998</td>\n",
       "      <td>241.729996</td>\n",
       "      <td>24093300</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-17 00:00:00-05:00</th>\n",
       "      <td>237.779999</td>\n",
       "      <td>243.250000</td>\n",
       "      <td>237.630005</td>\n",
       "      <td>241.679993</td>\n",
       "      <td>23123500</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-18 00:00:00-05:00</th>\n",
       "      <td>243.509995</td>\n",
       "      <td>243.740005</td>\n",
       "      <td>239.029999</td>\n",
       "      <td>241.220001</td>\n",
       "      <td>27591800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-21 00:00:00-05:00</th>\n",
       "      <td>241.429993</td>\n",
       "      <td>244.669998</td>\n",
       "      <td>241.190002</td>\n",
       "      <td>242.050003</td>\n",
       "      <td>26394700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-22 00:00:00-05:00</th>\n",
       "      <td>243.589996</td>\n",
       "      <td>245.309998</td>\n",
       "      <td>240.710007</td>\n",
       "      <td>245.029999</td>\n",
       "      <td>19665700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-23 00:00:00-05:00</th>\n",
       "      <td>245.110001</td>\n",
       "      <td>248.279999</td>\n",
       "      <td>244.270004</td>\n",
       "      <td>247.580002</td>\n",
       "      <td>19508500</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25 00:00:00-05:00</th>\n",
       "      <td>247.309998</td>\n",
       "      <td>248.699997</td>\n",
       "      <td>246.729996</td>\n",
       "      <td>247.490005</td>\n",
       "      <td>9200800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28 00:00:00-05:00</th>\n",
       "      <td>246.080002</td>\n",
       "      <td>246.649994</td>\n",
       "      <td>240.800003</td>\n",
       "      <td>241.759995</td>\n",
       "      <td>24778200</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-29 00:00:00-05:00</th>\n",
       "      <td>241.399994</td>\n",
       "      <td>242.789993</td>\n",
       "      <td>238.210007</td>\n",
       "      <td>240.330002</td>\n",
       "      <td>17948900</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30 00:00:00-05:00</th>\n",
       "      <td>240.570007</td>\n",
       "      <td>243.934998</td>\n",
       "      <td>239.860001</td>\n",
       "      <td>241.815002</td>\n",
       "      <td>6876503</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2022-11-02 00:00:00-04:00  228.815173  230.649998  219.421632  219.481476   \n",
       "2022-11-03 00:00:00-04:00  219.471488  219.790596  213.378658  213.647903   \n",
       "2022-11-04 00:00:00-04:00  216.938633  220.967272  212.830200  220.767838   \n",
       "2022-11-07 00:00:00-05:00  221.366164  227.768121  220.658153  227.229630   \n",
       "2022-11-08 00:00:00-05:00  228.057301  230.999008  225.205338  228.226822   \n",
       "2022-11-09 00:00:00-05:00  226.731038  227.987506  223.699587  223.879074   \n",
       "2022-11-10 00:00:00-05:00  234.768379  242.646187  234.339595  242.297165   \n",
       "2022-11-11 00:00:00-05:00  242.307141  247.293090  241.250107  246.415558   \n",
       "2022-11-14 00:00:00-05:00  241.309951  243.224554  238.537765  240.871185   \n",
       "2022-11-15 00:00:00-05:00  244.969641  246.305872  239.355458  241.290009   \n",
       "2022-11-16 00:00:00-05:00  242.789993  243.800003  240.419998  241.729996   \n",
       "2022-11-17 00:00:00-05:00  237.779999  243.250000  237.630005  241.679993   \n",
       "2022-11-18 00:00:00-05:00  243.509995  243.740005  239.029999  241.220001   \n",
       "2022-11-21 00:00:00-05:00  241.429993  244.669998  241.190002  242.050003   \n",
       "2022-11-22 00:00:00-05:00  243.589996  245.309998  240.710007  245.029999   \n",
       "2022-11-23 00:00:00-05:00  245.110001  248.279999  244.270004  247.580002   \n",
       "2022-11-25 00:00:00-05:00  247.309998  248.699997  246.729996  247.490005   \n",
       "2022-11-28 00:00:00-05:00  246.080002  246.649994  240.800003  241.759995   \n",
       "2022-11-29 00:00:00-05:00  241.399994  242.789993  238.210007  240.330002   \n",
       "2022-11-30 00:00:00-05:00  240.570007  243.934998  239.860001  241.815002   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Date                                                          \n",
       "2022-11-02 00:00:00-04:00  38407000       0.00             0  \n",
       "2022-11-03 00:00:00-04:00  36633900       0.00             0  \n",
       "2022-11-04 00:00:00-04:00  36767800       0.00             0  \n",
       "2022-11-07 00:00:00-05:00  33498000       0.00             0  \n",
       "2022-11-08 00:00:00-05:00  28192500       0.00             0  \n",
       "2022-11-09 00:00:00-05:00  27852900       0.00             0  \n",
       "2022-11-10 00:00:00-05:00  46268000       0.00             0  \n",
       "2022-11-11 00:00:00-05:00  34600900       0.00             0  \n",
       "2022-11-14 00:00:00-05:00  31123300       0.00             0  \n",
       "2022-11-15 00:00:00-05:00  31390100       0.00             0  \n",
       "2022-11-16 00:00:00-05:00  24093300       0.68             0  \n",
       "2022-11-17 00:00:00-05:00  23123500       0.00             0  \n",
       "2022-11-18 00:00:00-05:00  27591800       0.00             0  \n",
       "2022-11-21 00:00:00-05:00  26394700       0.00             0  \n",
       "2022-11-22 00:00:00-05:00  19665700       0.00             0  \n",
       "2022-11-23 00:00:00-05:00  19508500       0.00             0  \n",
       "2022-11-25 00:00:00-05:00   9200800       0.00             0  \n",
       "2022-11-28 00:00:00-05:00  24778200       0.00             0  \n",
       "2022-11-29 00:00:00-05:00  17948900       0.00             0  \n",
       "2022-11-30 00:00:00-05:00   6876503       0.00             0  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('final-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "937ac2121f4bd33c921bc04ce0336a5d7e4eb91bbd651e21166683a68e8f5aa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
