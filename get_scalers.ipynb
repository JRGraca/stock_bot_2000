{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_ta as pta\n",
    "import ta\n",
    "# from datapackage import Package\n",
    "# from selenium import webdriver\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import yfinance as yf\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import array\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import graphviz\n",
    "import pydot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## routine used to save scalers, because I forgot about it the first run\n",
    "\n",
    "top_25 = [\"AAPL\", \"MSFT\", \"AMZN\", \"TSLA\", \"GOOGL\", \"BRK.B\", \"UNH\", \"JNJ\", \"XOM\", \"JPM\", \"META\", \"V\", \"PG\", \"NVDA\", \"HD\", \"CVX\", \"LLY\", \"MA\", \"ABBV\", \"PFE\", \"MRK\", \"PEP\", \"BAC\", \"KO\"]\n",
    "\n",
    "for ticker_code in top_25:\n",
    "\tdataset = pd.read_csv(\"data/\" + ticker_code + \".csv\")\n",
    "\tshift = -1\n",
    "\tdataset = dataset.drop(columns=[\"Date\", \"Dividends\", \"Stock Splits\"])\n",
    "\ttrain_set_len = int(len(dataset) * 0.8)\n",
    "\ttrain_set = dataset[:train_set_len]\n",
    "\ttest_set = dataset[train_set_len:]\n",
    "\tX_train = train_set.drop(columns=[\"Close\"])[:shift]\n",
    "\ty_train = train_set[\"Close\"].shift(shift).dropna()\n",
    "\tX_test = test_set.drop(columns=[\"Close\"])[:shift]\n",
    "\ty_test = test_set[\"Close\"].shift(shift).dropna()\n",
    "\tx_scaler = MinMaxScaler()\n",
    "\ty_scaler = MinMaxScaler()\n",
    "\tX_train_scaled = x_scaler.fit_transform(X_train)\n",
    "\ty_train_scaled = y_scaler.fit_transform(np.array(y_train).reshape(-1,1))\n",
    "\tX_test_scaled = x_scaler.transform(X_test)\n",
    "\ty_test_scaled = y_scaler.transform(np.array(y_test).reshape(-1,1))\n",
    "\tpd.to_pickle(x_scaler, \"scalers/\" + str(ticker_code) + \"_x_scaler.pkl\")\n",
    "\tpd.to_pickle(y_scaler, \"scalers/\" + str(ticker_code) + \"_y_scaler.pkl\")\n",
    "\t# pd.to_pickle(train_set, \"train_sets/\" + ticker_code + \"_train_set.pkl\")\n",
    "\t# pd.to_pickle(test_set, \"test_sets/\" + ticker_code + \"_test_set.pkl\")\n",
    "\t# pd.to_pickle(X_train, \"sets/X_train/\" + ticker_code + \"_X_train.pkl\")\n",
    "\t# pd.to_pickle(X_test, \"sets/X_test/\" + ticker_code + \"_X_test.pkl\")\n",
    "\t# pd.to_pickle(y_train, \"sets/y_train/\" + ticker_code + \"_y_train.pkl\")\n",
    "\t# pd.to_pickle(y_test, \"sets/y_test/\" + ticker_code + \"_y_test.pkl\")\n",
    "\t# pd.to_pickle(X_train_scaled, \"sets/X_train/\" + ticker_code + \"_X_train_scaled.pkl\")\n",
    "\t# pd.to_pickle(X_test_scaled, \"sets/X_test/\" + ticker_code + \"_X_test_scaled.pkl\")\n",
    "\t# pd.to_pickle(y_train_scaled, \"sets/y_train/\" + ticker_code + \"_y_train_scaled.pkl\")\n",
    "\t# pd.to_pickle(y_test_scaled, \"sets/y_test/\" + ticker_code + \"_y_test_scaled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87067052],\n",
       "       [0.87037283],\n",
       "       [0.87781289],\n",
       "       ...,\n",
       "       [2.69865875],\n",
       "       [2.70124551],\n",
       "       [2.70728167]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20.23145103],\n",
       "       [20.22454643],\n",
       "       [20.39711189],\n",
       "       ...,\n",
       "       [62.63000107],\n",
       "       [62.68999863],\n",
       "       [62.83000183]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scaler.inverse_transform(y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12266    20.231451\n",
       "12267    20.224546\n",
       "12268    20.397112\n",
       "12269    20.279770\n",
       "12270    20.196938\n",
       "           ...    \n",
       "15327    62.080002\n",
       "15328    62.349998\n",
       "15329    62.630001\n",
       "15330    62.689999\n",
       "15331    62.830002\n",
       "Name: Close, Length: 3066, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('final-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "937ac2121f4bd33c921bc04ce0336a5d7e4eb91bbd651e21166683a68e8f5aa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
